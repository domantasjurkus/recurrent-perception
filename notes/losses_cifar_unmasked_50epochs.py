import numpy as np
import matplotlib.pyplot as plt

'''
Correct predictions: [1368, 1240, 1120, 1537]
Total test samples:  [1564, 1622, 1489, 1655]
Test accuracy: 83 %
tensor([[ 1368,   142,    48,     6],
        [  271,  1240,   106,     5],
        [  131,   179,  1120,    59],
        [   42,    16,    60,  1537]], dtype=torch.int32)
Finished Training
Training losses: [111.13983595371246, 110.42197692394257, 96.69245314598083, 77.96951395273209, 71.35763329267502, 67.02774220705032, 63.571997463703156, 60.49640226364136, 58.016316294670105, 56.01366600394249, 54.069702446460724, 52.94919568300247, 51.79471653699875, 50.87372240424156, 49.71047857403755, 48.7312775850296, 47.48615276813507, 46.694905161857605, 46.08695477247238, 45.35861721634865, 44.464422434568405, 43.51264747977257, 42.68848107755184, 42.16225826740265, 41.67403510212898, 40.77355870604515, 40.59741775691509, 40.158224046230316, 39.463659793138504, 38.62918284535408, 38.576124995946884, 37.72463113069534, 38.36842608451843, 37.99923774600029, 36.68699398636818, 36.210563972592354, 36.34738439321518, 36.31925210356712, 35.51936736702919, 34.887226954102516, 34.905374363064766, 34.514858692884445, 34.402281671762466, 34.31133568286896, 33.75562387704849, 33.25396600365639, 33.89970152080059, 33.306378319859505, 32.7187125980854, 32.323388397693634]
Testing losses: [137.30293929576874, 134.2667932510376, 100.6568571254611, 92.54029059410095, 84.00954538397491, 79.01213387958705, 75.96737794950604, 72.60300143063068, 70.60855852812529, 68.25779639184475, 69.471345461905, 63.6727390140295, 62.37589191459119, 61.40392239019275, 60.46727672033012, 58.52766408864409, 58.40365444961935, 56.545103741809726, 56.48854611068964, 55.467546213418245, 54.24326092982665, 53.96365588158369, 52.45577632635832, 52.6507351314649, 51.68502245238051, 51.83899298380129, 51.07567335944623, 49.29083454981446, 49.08491808595136, 49.18672562902793, 48.066653409041464, 48.94010722776875, 49.021197189576924, 46.268877673195675, 45.41495333937928, 46.265345788095146, 45.48800822882913, 45.337970552034676, 44.23919110558927, 44.20567972864956, 44.48788270051591, 43.693209083750844, 42.7863373470027, 42.75511890091002, 43.25455630477518, 42.645612738095224, 42.869595563970506, 41.101690266281366, 41.84133631689474,41.716533703613095]
'''

all_categories = ['pant', 'shirt', 'sweater', 'tshirt']

confusion = np.array([[ 1368.0,   142.0,    48.0,     6.0],
        [  271,  1240,   106,     5],
        [  131,   179,  1120,    59],
        [   42,    16,    60,  1537]])

def confusion_matrix(confusion):
    # Normalize by dividing every row by its sum
    for i in range(len(all_categories)):
        confusion[i] = confusion[i] / confusion[i].sum()

    # Set up plot
    fig = plt.figure()
    ax = fig.add_subplot(111)
    cax = ax.matshow(confusion)
    fig.colorbar(cax)
    plt.xlabel('prediction', labelpad=15)
    plt.ylabel('actual', labelpad=15)

    # Set up axes
    ax.set_xticklabels([''] + all_categories)
    ax.set_yticklabels([''] + all_categories)

    # Force label at every tick
#     ax.xaxis.set_major_locator(ticker.MultipleLocator(1))
#     ax.yaxis.set_major_locator(ticker.MultipleLocator(1))


    for (i, j), z in np.ndenumerate(confusion):
        ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center',
                bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))

    # sphinx_gallery_thumbnail_number = 2
    plt.show()

confusion_matrix(confusion)